{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "da7e0f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import bernoulli\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dccbfb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BernoulliBandit :\n",
    "    def __init__ (self , means):\n",
    "        for i in means:\n",
    "            assert(i <= 1 and i >= 0)\n",
    "        self.means = means\n",
    "        self.k = len(means)\n",
    "        self.best_mean = max(means)\n",
    "        self.regret = 0\n",
    "# Function should return the number of arms\n",
    "    def get_K( self ):\n",
    "         return self.k\n",
    "# Accepts a parameter 0 <= a <= K -1 and returns the\n",
    "# realisation of random variable X with P(X = 1) being\n",
    "# the mean of the (a +1) th arm .\n",
    "    def pull (self , a):\n",
    "        self.regret += (self.best_mean - self.means[a])\n",
    "        return bernoulli.rvs(self.means[a], size=1)\n",
    "\n",
    "    def get_regret ( self ):\n",
    "        return self.regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5fb1913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ETC(n, m, bandit):\n",
    "    k = bandit.k\n",
    "    rewards= np.zeros(n)\n",
    "    total_reward=0\n",
    "    actions = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        if(i<= m*k - 1):\n",
    "            rewards[i] = bandit.pull(i%k)\n",
    "            total_reward += rewards[i]\n",
    "            actions[i] = i%k\n",
    "        else: \n",
    "            if(i == m*k): ##optimization\n",
    "                best_mean_index = np.argmax(np.mean(np.transpose(np.reshape(rewards[0:m*k], (m,k))),1))\n",
    "            actions[i] = best_mean_index\n",
    "            rewards[i] = bandit.pull(best_mean_index)\n",
    "            total_reward += rewards[i]\n",
    "    observed_random_regret = n * bandit.best_mean - total_reward\n",
    "    return np.array([(i,j) for (i,j) in zip(actions,rewards)]), observed_random_regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c27cf4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [1., 0.],\n",
       "       [2., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [2., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [2., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [2., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [2., 1.],\n",
       "       [2., 1.],\n",
       "       [2., 1.],\n",
       "       [2., 1.],\n",
       "       [2., 0.],\n",
       "       [2., 1.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit = BernoulliBandit([0.3,0.6,0.9])\n",
    "ETC(100,5,bandit)[0][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8b2bb0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 100\n",
    "horizon = 500\n",
    "mean_regrets = np.zeros(50)\n",
    "for m in range(2,101,2): ## m = [2,4,...,50]\n",
    "    for i in range(trials):\n",
    "        bandit= BernoulliBandit([0.5,0.6,0.7])\n",
    "        results, observed_random_regret = ETC(horizon,m,bandit)\n",
    "        mean_regrets[int(m/2) - 1] = (mean_regrets[int(m/2) - 1] * i + bandit.get_regret())/(i+1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a52e3aff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x23c3abfc8e0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.scatter(range(2,101,2), mean_regrets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9e63f3",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## 6.1\n",
    "$\\hat{\\mu}_i(mk) = \\frac{1}{T_i(mk)}\\sum^{mk}_{s=1}\\mathbb{1}(A_s=1)X_s$\n",
    "By the canonical model, every non-zero term in the sum is drawn from $\\mathbb{P}_{A_i}(.)$ distribution which is 1-subgaussian. And by the algorithm there are m non-zero terms.\n",
    "show that $\\frac{1}{m}(\\sum^m_1X_t + \\sum^m_1X_1)$ is $\\sqrt{\\frac{2}{m}}-subgaussian$.\n",
    "How to deal with the added constant?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a7d8e8",
   "metadata": {},
   "source": [
    "## 6.2\n",
    "### Case 1:\n",
    "$\\Delta \\leq \\frac{1}{\\sqrt{n}}$:\n",
    "\n",
    "$R_n \\leq n\\Delta \\leq \\sqrt{n}$\n",
    "\n",
    "### Case 2:\n",
    "$\\Delta \\geq \\frac{1}{\\sqrt{n}}$:\n",
    "\n",
    "$R_n \\leq \\Delta + \\frac{4}{\\Delta}\\Bigl(1+max\\{0, log(\\frac{n\\Delta^2}{4})\\}\\Bigr)$\n",
    "\n",
    "$R_n \\leq \\Delta + 4\\sqrt{n} + \\max_{\\Delta'>0}\\frac{4}{\\Delta'}log(\\frac{n\\Delta'^2}{4})$\n",
    "\n",
    "Finding the first derivative for the right-most term and equating to 0:\n",
    "\n",
    "$\\frac{8}{\\Delta'^2}-\\frac{4}{\\Delta'^2}log(\\frac{n\\Delta'^2}{4}) = 0$\n",
    "\n",
    "Evaluting, we get $\\Delta' = \\frac{2e}{\\sqrt{n}}$\n",
    "\n",
    "Can check that the second derivate is negative.\n",
    "\n",
    "Substituting, we get:\n",
    "\n",
    "$R_n \\leq \\Delta + 4\\sqrt{n} + \\frac{4\\sqrt{n}}{e} \\leq \\Delta + (4+\\frac{4}{e})\\sqrt{n}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5eec21",
   "metadata": {},
   "source": [
    "# 6.3\n",
    "\n",
    "Assuming that n>2m, and let $\\Delta_2$ be the suboptimality gap of the suboptimal arm, we have that:\n",
    "\n",
    "$\\mathbb{P}(T_2(n)>m) \\leq \\mathbb{P}(\\hat{\\mu}_2(2m) - \\hat{\\mu_2} + \\mu_1 - \\mu_2 \\geq \\Delta_2) \\leq exp(-\\frac{m\\Delta^2}{4})$ as seen before.\n",
    "\n",
    "Setting $m = \\frac{4}{\\Delta^2}log(\\frac{1}{\\delta})$ would yield:\n",
    "\n",
    "$\\mathbb{P}(T_2(n) >m) \\leq \\delta$\n",
    "\n",
    "We thus have the bound on the pseudo-regret with probability 1-$\\delta$:\n",
    "\n",
    "$\\bar{R}_n \\leq m\\Delta_2 = \\frac{4}{\\Delta_2}log(\\frac{1}{\\delta})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ef75f4",
   "metadata": {},
   "source": [
    "# 6.4\n",
    "\n",
    "We need:\n",
    "$\\mathbb{P}(n\\mu^*-\\sum^n_{t=1}X_t \\leq \\epsilon) = 1- \\delta$\n",
    "We have that:\n",
    "\n",
    "$\\mathbb{P}(n\\mu^*-\\sum^n_{t=1}X_t \\leq \\epsilon) = \\mathbb{P}(\\sum^n_{t=1}X_t - n\\mu^* \\geq -\\epsilon) \\leq exp(-\\frac{(\\epsilon)^2}{2n})$ \n",
    "\n",
    "Since $\\sum^n_{t=1}X_t - n\\mu^*$ is $\\sqrt{n}-subgaussian$.\n",
    "\n",
    "setting $\\epsilon = \\sqrt{2nlog(\\frac{1}{1-\\delta})}$ will give us the bound:\n",
    "$R_n < \\sqrt{2nlog(\\frac{1}{1-\\delta})}$ with probability $1-\\delta$\n",
    "\n",
    "We conclude that the $1-\\delta$-probaility bound for the random regret is in O($\\sqrt{n}$) whereas for the pseudo-regret, it is in O(1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7fdc27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
